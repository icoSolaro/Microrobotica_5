import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier # classificatore multi-layer-Perceptron


def scatter_plot(ax, x_name, y_name, categoria):
    for cat in data[categoria].unique():
        data_cat=data[data[categoria]==cat]
        ax.scatter(data_cat[x_name], data_cat[y_name], s=5, label=cat)
    ax.set_xlabel(x_name)
    ax.set_ylabel(y_name)
    #ax.legend()

def histogram_plot(ax, x_name, categoria):
    for cat in data[categoria].unique():
        data_cat=data[data[categoria]==cat]
        ax.hist(data_cat[x_name], bins=15 , label=cat, alpha=0.5)
    ax.set_xlabel(x_name)
    ax.set_ylabel("Frequenza assoluta")
    #ax.legend()

def analizzaDataset(data, categoria, nomeFile):
    validCols = [data[d].dtype!="object" for d in data]
    cols_numeriche=data.columns[validCols]
    n=len(cols_numeriche)    
    fig, axs = plt.subplots(figsize=(32, 32), nrows=n, ncols=n)
    for i, col_1 in enumerate(cols_numeriche):
        for j, col_2 in enumerate(cols_numeriche):
            if i!=j:
                scatter_plot(axs[i, j], col_1 , col_2, categoria)
            else:
                histogram_plot(axs[i, j], col_1, categoria)
    
    fig.legend(data[categoria].unique(), loc="center left", fontsize="xx-large")
    plt.savefig(nomeFile)
    plt.show()
    





data=pd.read_csv("./titanic.csv")


data.head()


data.info()


data.describe()


analizzaDataset(data, "Survived", "titanic.pdf")


data["sex_num"]=(data["Sex"]=="female").astype(np.int64)

data["sex_num"]


data.head()


analizzaDataset(data, "Survived", "./titanic.pdf")





data["Pclass"].value_counts()# numero di persone su ogni classe


data[["Pclass", "Name"]].groupby("Pclass").count() # numero di persone su ogni classe


data[["Pclass", "Fare"]].groupby("Pclass").mean() #media del biglietto per classe


data[["Pclass", "Sex"]].value_counts()#


#soffermandoci sui bambini, numero morti, numero soprevvissuti: (bambino sotto 14 anni)
data[data["Age"]<14]["Survived"].value_counts()


#chi aveva figli o genitori a bordo ha delle possibilità in più di sopravvivere

#prima aggiungiamo colonna se aveva genitori, figli a bordo

data["parents_children"]=[0 if s==0 else 1 for s in data["Parents/Children Aboard"]]
#data.head(10)
data[["parents_children", "Survived"]].value_counts()


sex_labelencoder=LabelEncoder()
data["Sex_numeric"]=sex_labelencoder.fit_transform(data["Sex"]) #restituisce un array np che aggiungiamo al dataframe. intanto impara quali sono le categorie


sex_labelencoder.classes_# Ha le classi in cui ha diviso


sex_labelencoder.transform(["male", "female"])


sex_labelencoder.inverse_transform([1,1,0,1])


data.columns


feature_cols = ['Pclass', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare', 'Sex_numeric']
output=['Survived']


X=data[feature_cols].to_numpy()
y=data[output].to_numpy()





#NORMALIZZAZIONE una features significa fare in modo che abbia media 0 e deviazione standard 1
pclass=X[:,0]
#pclass-np.mean(pclass) #avrebbe media 0ù
#vogliamo che abbia deviazione standard 1. vogliamo che tutte le colonne siano con media 0 e deviazione standard ugale tra loro. Così abbiamo mappato tutte le colonne sullo stesso range
pclass_normalizzata=(pclass-np.mean(pclass))/np.std(pclass)
data["pclass_normalizzata"]=pclass_normalizzata





fis, axs = plt.subplots(ncols=2, nrows=1, figsize=(10, 5))

histogram_plot(axs[0], "Pclass", "Survived")
for survived in data["Survived"].unique():
    data_survived = data[data["Survived"] == survived]
    axs[1].hist(data_survived["pclass_normalizzata"], bins=15, label=survived, alpha=0.5)
axs[1].set_xlabel("pclass_normalizzata")
axs[1].set_ylabel("Frequenza assoluta")
axs[1].legend()

plt.show()





features_scaler=StandardScaler()
X_norm=features_scaler.fit_transform(X)


X_norm.dtype


# features_scaler.transform([1,])


X_train, X_test, y_train, y_test= train_test_split(X_norm, y, test_size=0.33, random_state=42)


neural_network = MLPClassifier(hidden_layer_sizes=(4,3), max_iter=1000) # rete neurale non addestrata


neural_network.fit(X_train, y_train.reshape(-1)) #y_train è un array unoD in colonne, vuole le righe
#addestrare una funzione vuol dire trovare il minimo della funzione, visto che la funzione non è derivabile usa dei passsaggi numero di passaggi=max_iter


neural_network.score(X_train, y_train)





neural_network.score(X_test, y_test)


neural_network.score(X_train, y_train)





from joblib import dump, load
dump(neural_network, "titanic.joblib")





feature_cols = ['Pclass', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare', 'Sex_numeric']

johndoe=np.array([[2, 18, 1, 2, 20, 0]]) # deve essere una matrice np
johndoe #dobbiamo avere dei valori normalizzati


johndoe_norm=features_scaler.transform(johndoe)
johndoe_norm


neural_network.predict(johndoe_norm) #DEVE ESSERE NORMALIZZATO



neural_network.predict_proba(johndoe_norm) 






